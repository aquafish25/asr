
# ğŸ—£ï¸ wav2vec2 Speech Recognition Pipeline

Welcome to the **wav2vec2 ASR pipeline** â€” a PyTorch-powered, Hugging Face-free, fully customizable training and evaluation loop for automatic speech recognition. Built on top of `torchaudio`â€™s pretrained Wav2Vec 2.0 model, this repo gives you full control over data handling, training, validation, and decoding â€” no black-box abstractions here.

## ğŸš€ Whatâ€™s Inside?

- ğŸ§  **Model**: `torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_100H`
- ğŸ§¾ **Loss Function**: Custom CTC loss (blank token = 0)
- ğŸ“Š **Metric**: Word Error Rate (via `jiwer`)
- ğŸ“ **Data**: Custom `Dataset` for audio-transcript pairs from a CSV
- ğŸ” **Training & Validation**: Custom loops with audio padding, gradient clipping, and logging

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ wav2vec2.py        # Main training + evaluation script
â”œâ”€â”€ README.md          # Youâ€™re here!
â”œâ”€â”€ your_dataset.csv   # Your audio file paths and transcripts
```

CSV format expected:
```csv
path,transcript
/path/to/audio1.wav,hello world
/path/to/audio2.wav,open the pod bay doors
...
```

---

## âš™ï¸ Setup

First, clone this repo and install the dependencies:

```bash
git clone https://github.com/yourusername/wav2vec2-asr-pipeline.git
cd wav2vec2-asr-pipeline
pip install torch torchaudio pandas jiwer
```

---

## ğŸ“ Train Your Model

Update the dataset path in `main()` of `wav2vec2.py`:

```python
df = pd.read_csv("/path/to/your_dataset.csv")
```

Then simply run:

```bash
python wav2vec2.py
```

This will:
1. Split your dataset (80% train, 10% val, 10% test)
2. Train the model (100 epochs by default)
3. Validate each epoch
4. Evaluate on the test set (prints sample predictions and final WER)
5. Save the model to `wav2vec2.pt`

---


## ğŸ› ï¸ Customization

Feel free to modify:
- ğŸ”¡ **Tokenizer** in `tokenize()` if you're using a custom vocabulary
- ğŸ“‰ **Loss or optimizer** to experiment with training
- ğŸ—‚ï¸ **DataLoader batch size or augmentations**
- ğŸ“ˆ **Epoch count / learning rate / scheduler**

---

## âš ï¸ Known Issues / Gotchas

- Make sure your audio sample rate matches `16kHz` or it will be resampled.
- Empty or too-short transcripts may be skipped or default to blank token `0`.
- Modelâ€™s feature extractor is frozen â€” adjust that if you want full fine-tuning.

---

## ğŸ“¬ Questions or Suggestions?

Open an [issue](https://github.com/yourusername/wav2vec2-asr-pipeline/issues) or feel free to fork and customize!

---
